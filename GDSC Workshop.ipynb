{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "F_HoEuDrStYH"
      },
      "outputs": [],
      "source": [
        "!pip install -q elevenlabs -U\n",
        "!pip install -q  google-generativeai"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "641yucmZqhBf"
      },
      "outputs": [],
      "source": [
        "import elevenlabs\n",
        "import PIL\n",
        "import google.generativeai as genai\n",
        "import time\n",
        "from elevenlabs import generate\n",
        "from google.colab import userdata\n",
        "from IPython.display import Audio, display, Javascript, Image\n",
        "from google.colab.output import eval_js\n",
        "from base64 import b64decode\n",
        "\n",
        "# Api keys\n",
        "genai.configure(api_key=userdata.get('gemini')) # gemini\n",
        "elevenlabs.set_api_key(userdata.get('elevenlabs')) # 11ElevenLabs\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "8-s1_XXETYzU"
      },
      "outputs": [],
      "source": [
        "# Set up the model\n",
        "generation_config = {\n",
        "  \"temperature\": 0.5,\n",
        "  \"top_p\": 1,\n",
        "  \"top_k\": 1,\n",
        "  \"max_output_tokens\": 512,\n",
        "}\n",
        "# Safety settings for the model\n",
        "safety_settings = [\n",
        "  {\n",
        "    \"category\": \"HARM_CATEGORY_HARASSMENT\",\n",
        "    \"threshold\": \"BLOCK_MEDIUM_AND_ABOVE\"\n",
        "  },\n",
        "  {\n",
        "    \"category\": \"HARM_CATEGORY_HATE_SPEECH\",\n",
        "    \"threshold\": \"BLOCK_MEDIUM_AND_ABOVE\"\n",
        "  },\n",
        "  {\n",
        "    \"category\": \"HARM_CATEGORY_SEXUALLY_EXPLICIT\",\n",
        "    \"threshold\": \"BLOCK_MEDIUM_AND_ABOVE\"\n",
        "  },\n",
        "  {\n",
        "    \"category\": \"HARM_CATEGORY_DANGEROUS_CONTENT\",\n",
        "    \"threshold\": \"BLOCK_MEDIUM_AND_ABOVE\"\n",
        "  },\n",
        "]\n",
        "\n",
        "# Gemini model\n",
        "model = genai.GenerativeModel(model_name=\"gemini-pro-vision\", generation_config=generation_config,\n",
        "                              safety_settings=safety_settings)\n",
        "\n",
        "# Taking the photo from webcam\n",
        "def take_photo(filename='photo.jpg', quality=0.8):\n",
        "  js = Javascript('''\n",
        "    async function takePhoto(quality) {\n",
        "      const div = document.createElement('div');\n",
        "\n",
        "      const video = document.createElement('video');\n",
        "      video.style.display = 'block';\n",
        "      const stream = await navigator.mediaDevices.getUserMedia({video: true});\n",
        "\n",
        "      document.body.appendChild(div);\n",
        "      div.appendChild(video);\n",
        "      video.srcObject = stream;\n",
        "      await video.play();\n",
        "\n",
        "      // Resize the output to fit the video element.\n",
        "      google.colab.output.setIframeHeight(document.documentElement.scrollHeight, true);\n",
        "\n",
        "      // Wait for Capture to be clicked.\n",
        "      await new Promise((resolve)=>{\n",
        "        setTimeout(()=>{return resolve(\"Done\")}, 5000)\n",
        "      })\n",
        "\n",
        "      const canvas = document.createElement('canvas');\n",
        "      canvas.width = video.videoWidth;\n",
        "      canvas.height = video.videoHeight;\n",
        "      canvas.getContext('2d').drawImage(video, 0, 0);\n",
        "      stream.getVideoTracks()[0].stop();\n",
        "      div.remove();\n",
        "      return canvas.toDataURL('image/jpeg', quality);\n",
        "    }\n",
        "    ''')\n",
        "  display(js)\n",
        "  data = eval_js('takePhoto({})'.format(quality))\n",
        "  binary = b64decode(data.split(',')[1])\n",
        "  with open(filename, 'wb') as f:\n",
        "    f.write(binary)\n",
        "  return filename\n",
        "\n",
        "# Get the generative Text\n",
        "response = None\n",
        "def analyze_image(image, script):\n",
        "  input_text = \"{\\n\\\"role\\\": \\\"system\\\",\\n\\\"content\\\": \\\"\\\"\\\"You are Sir David Attenborough. Narrate the picture of the human as if it is a nature documentary.Make it snarky and funny. Don't repeat yourself. Make it short about 300 words. If I do anything remotely interesting, make a big deal about it!\\\"\\\"\\\",}\" + script + \"{\\n\\\"role\\\": \\\"user\\\",\\n\\\"content\\\": [{\\\"type\\\": \\\"text\\\", \\\"text\\\": \\\"Describe this image.\\\"},\\n]\\n}\"\n",
        "  global response\n",
        "  response = model.generate_content([input_text, image])\n",
        "  response.resolve()\n",
        "  try:\n",
        "    return response.candidates[0].content.parts[0].text\n",
        "  except:\n",
        "    print(\"An exception occurred\")\n",
        "    return \"\"\n",
        "\n",
        "# Play audio using 11Labs\n",
        "def play_audio(text):\n",
        "  audio = generate(\n",
        "    text=text,\n",
        "    voice=\"Daniel\",\n",
        "    model=\"eleven_multilingual_v1\"\n",
        "  )\n",
        "  display(Audio(audio, autoplay=True))\n",
        "  time.sleep(max(2,(len(audio)/16429.0) - 15))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "c059YaceEg1b"
      },
      "outputs": [],
      "source": [
        "########################################## camera -> image -> text -> audio ######################################################\n",
        "def camera2audio():\n",
        "  script = \"\"\n",
        "  while True:\n",
        "    # path to your image\n",
        "    image_path = \"photo.jpg\"\n",
        "\n",
        "    # Taking Image from camera\n",
        "    filename = take_photo(filename = image_path)\n",
        "    print(\"üì∏ Say cheese! Saving frame.\")\n",
        "    display(Image(filename))\n",
        "\n",
        "    # opening image using PIL\n",
        "    img = PIL.Image.open(image_path)\n",
        "\n",
        "    # analyze posture\n",
        "    print(\"üëÄ David is watching...\")\n",
        "    analysis = analyze_image(img, script=script)\n",
        "\n",
        "    # print(analysis)\n",
        "    if(analysis!=\"\"):\n",
        "      print(\"üéôÔ∏è David says:\")\n",
        "      play_audio(analysis)\n",
        "\n",
        "      script = script + f\"\\n{analysis}\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9fRV-N-lzAXE"
      },
      "outputs": [],
      "source": [
        "camera2audio()"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
